import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from urllib.parse import quote
from io import BytesIO

# ğŸ§  æ¨™æ¡ˆç¨®é¡èˆ‡å°æ‡‰åƒæ•¸å°ç…§
type_map = {
    "æ‹›æ¨™": "tenderDeclaration",
    "æ±ºæ¨™": "award",
    "å…¬é–‹é–±è¦½åŠå…¬é–‹å¾µæ±‚": "publicReview",
    "æ”¿åºœæ¡è³¼é å‘Š": "procurementForecast",
}

# ğŸŒ æŠ“å–è³‡æ–™å‡½å¼
def fetch_tenders(keyword, tender_type, year):
    base_url = "https://web.pcc.gov.tw/prkms/tender/common/bulletion/readBulletion"
    params = {
        "querySentence": keyword,
        "tenderStatusType": tender_type,
        "sortCol": "AWARD_NOTICE_DATE",
        "timeRange": year,
        "pageSize": 100,
    }

    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    res = requests.get(base_url, params=params, headers=headers)

    if res.status_code != 200:
        st.warning(f"âš ï¸ {year} å¹´è³‡æ–™æ“·å–å¤±æ•—ï¼ˆHTTP {res.status_code}ï¼‰")
        return []

    soup = BeautifulSoup(res.text, "html.parser")
    table = soup.find("table")
    if not table:
        st.info(f"ğŸ“­ {year} å¹´æ²’æœ‰æ‰¾åˆ°è³‡æ–™è¡¨æ ¼ã€‚")
        return []

    rows = table.find_all("tr")
    data = []
    for row in rows[1:]:  # è·³éè¡¨é ­
        cols = row.find_all("td")
        if len(cols) >= 9:
            values = [col.get_text(strip=True) for col in cols[:9]]
            link_tag = cols[6].find("a")
            values[6] = link_tag["href"] if link_tag else values[6]
            data.append(values)

    return data

# ğŸ–¥ï¸ Streamlit UI
st.title("ğŸ” æ”¿åºœæ¨™æ¡ˆ_å¹´åº¦æ¨™æ¡ˆæŸ¥è©¢å·¥å…·")
st.subheader("ğŸ“Œ é–‹ç™¼è€…: cycy.exe, 2025")

a = st.text_input("è«‹è¼¸å…¥é—œéµå­—ï¼ˆä¾‹å¦‚ï¼šå…¬å¸åç¨±/æ¨™æ¡ˆé—œéµå­—ï¼‰", value="ä¹¾å¤æ¸¬ç¹ªç§‘æŠ€æœ‰é™å…¬å¸")
b = st.selectbox("æ¨™æ¡ˆç¨®é¡", list(type_map.keys()))
start_year = st.number_input("èµ·å§‹æ°‘åœ‹å¹´", min_value=97, max_value=114, value=110)
end_year = st.number_input("çµæŸæ°‘åœ‹å¹´", min_value=97, max_value=114, value=114)

if st.button("é–‹å§‹çˆ¬èŸ²ï¼Œç­‰ç­‰ä½ å°‡æœƒç²å¾—æ•´å€‹å®‡å®™ ğŸš€"):
    with st.spinner("ğŸ“¡ è³‡æ–™æŠ“å–ä¸­ï¼Œè«‹ç¨å€™..."):
        yearly_data = {}

        for year in range(start_year, end_year + 1):
            st.write(f"ğŸ“… æ­£åœ¨è™•ç†æ°‘åœ‹ {year} å¹´...")
            records = fetch_tenders(a, type_map[b], year)
            if records:
                df = pd.DataFrame(records, columns=["é …æ¬¡", "ç¨®é¡", "æ©Ÿé—œåç¨±", "æ¨™æ¡ˆåç¨±", "æ‹›æ¨™å…¬å‘Šæ—¥æœŸ", "æ±ºæ¨™å…¬å‘Šæ—¥æœŸ", "æ¨™æ¡ˆé€£çµ", "æ¬„ä½8", "æ¬„ä½9"])
                yearly_data[str(year)] = df

        if not yearly_data:
            st.error("ğŸ˜¢ æ²’æœ‰æ‰¾åˆ°ä»»ä½•è³‡æ–™ã€‚")
        else:
            st.success("âœ… è³‡æ–™æ“·å–å®Œæˆï¼")

            output = BytesIO()
            with pd.ExcelWriter(output, engine="openpyxl") as writer:
                for year, df in yearly_data.items():
                    df.to_excel(writer, sheet_name=year, index=False)

            st.download_button(
                label="â¬‡ï¸ ä¸‹è¼‰ Excel æª”",
                data=output.getvalue(),
                file_name=f"{start_year}-{end_year}_{a}_{b}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
